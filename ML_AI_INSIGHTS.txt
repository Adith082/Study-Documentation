-> Transformers excel under end-to-end fine-tuning while convolutional networks excel under linear probing (where only the model head is trained). This is an interesting point that should be explored. here, head means (fully connected layers + class labels (probably)) (source medium blog of salvator raieli)

-> 
Swin Transformer v2 (base-sized model)   (best backbone for classification tasks)  (source medium blog of salvator raieli)


-> ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders (best for other than classification tasks. although in classification
task. it is very close to Swin Transformer v2 (base-sized model) 
) (source medium blog of salvator raieli)

-> Self-supervised (SSL) backbones can outperform supervised pretraining with similar-sized pre-training datasets. This is good news because creating a supervised dataset is more expensive.  (source medium blog of salvator raieli)


-> self attention mechanism is inspired from bahdanau attention mechanism!


medical imaging + AI
--------------------

-> embedding can be said as a compression version of input data (image, text) that contains important information.

-> supervised contrastive learning? important stuff. do check on it please.

-> there is a visualization technique called T-distributed stochastic neighbor embedding or TC. Its like visualizing embeddings in a 2 dimensional way

-> AUC-ROC curve is actuallya tradeoff between true-positive and false-positive!

-> just like we can combine image with image for contrastive learning, we can do the same thing for image with text! and put them in the same embedding space.
   originally it was developed for CLIP, but then it was also applied for Chest X-rays ConVIRT, CheXero? please google CLIP, ConVIRT and CheXero 


-> what can we build if we have just access to embeddings?
        1. Zero-shot image classifiers.
        2. Text-to-Image retrievals.
        3. Report Generator.


-> classification vs segmentation vs detection


->  U-net is a great architecture for (semantic segmentation, not instance segmentation) segmenting biomedical image. nifty files are collection of dcom files (like 3d segmentation images)


-> Backpropagation can be of different types such as static backpropagation and recurrent back-propagation networks






